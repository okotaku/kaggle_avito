{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "folder = \"stack2nd/\"\n",
    "oof = pd.read_feather(\"oof2_all_test.feather\")\n",
    "test = pd.read_feather(\"test2_all_test.feather\")\n",
    "traindex = oof.item_id\n",
    "\n",
    "x = oof.drop([\"item_id\", \"y\"], axis=1).values\n",
    "y = oof.y.values\n",
    "test_id = test.item_id.values\n",
    "test_x = test.drop([\"item_id\"], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1503424, 64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03648105  0.06671315 -0.04710182 -0.10520438  0.00882287  0.01006139\n",
      "  0.2428907   0.0345227  -0.04119693 -0.01779218 -0.03516799 -0.0013355\n",
      " -0.09593122 -0.01710561 -0.01907652  0.45139154 -0.04811358 -0.03732844\n",
      " -0.03184909 -0.06102298 -0.03458024 -0.02872616 -0.14408183 -0.01255199\n",
      " -0.03523598  0.10343103 -0.02048007 -0.35830465  0.06480817 -0.09456323\n",
      "  0.10595159  0.06014987  0.04061017  0.02433172 -0.11422082 -0.03712398\n",
      " -0.06123426 -0.02575121 -0.11387563  0.20715065  0.02091696  0.11912121\n",
      "  0.03291356  0.19984827  0.25211151  0.14325107  0.13502712  0.2212015\n",
      " -0.19719694  0.05515071  0.04657492 -0.04653303  0.01595117  0.0151539\n",
      " -0.03938621 -0.03762645  0.09452845 -0.00627108  0.01528965  0.09799383\n",
      "  0.06669476  0.09448641  0.02392837 -0.06875766]\n",
      "test loss 0.20897676806386542\n",
      "[-0.02925252  0.06247082 -0.04388752 -0.10682964  0.00710844  0.00667241\n",
      "  0.24979745  0.0390078  -0.04351075 -0.01424417 -0.04074515  0.00226832\n",
      " -0.08686697 -0.02382923 -0.02368985  0.45687418 -0.04601569 -0.03660357\n",
      " -0.03713099 -0.06297064 -0.03318899 -0.0305424  -0.14712853 -0.01128391\n",
      " -0.03531925  0.10489347 -0.02317252 -0.35359571  0.05169865 -0.09766249\n",
      "  0.10915119  0.06039161  0.03905913  0.02307295 -0.11193828 -0.03430624\n",
      " -0.06328191 -0.02454943 -0.11471826  0.20243653  0.03201739  0.12353101\n",
      "  0.03303912  0.21079439  0.25297669  0.14986001  0.12519103  0.21415603\n",
      " -0.19042404  0.03919517  0.05361836 -0.053669    0.0085802   0.02064223\n",
      " -0.04542537 -0.02711041  0.10362776 -0.01015075  0.01214165  0.10107052\n",
      "  0.06208021  0.09694069  0.00562065 -0.05820176]\n",
      "test loss 0.20933822618936537\n",
      "[-0.02551443  0.06499744 -0.04557058 -0.10202693  0.00964162  0.00358161\n",
      "  0.23359189  0.03323771 -0.0325815  -0.0205967  -0.04246955 -0.00606086\n",
      " -0.09169835 -0.01624213 -0.01776769  0.46563837 -0.04467465 -0.03995689\n",
      " -0.03121554 -0.06352383 -0.03874216 -0.02997859 -0.14734908 -0.01582877\n",
      " -0.03667509  0.10392004 -0.02400605 -0.35856008  0.06180526 -0.09614615\n",
      "  0.10534139  0.05842873  0.04412018  0.02580236 -0.1135331  -0.03841899\n",
      " -0.06048574 -0.02428382 -0.11744215  0.21355689  0.03790161  0.11928975\n",
      "  0.03671936  0.20087122  0.25374501  0.15071684  0.13194381  0.22183764\n",
      " -0.19337477  0.03970183  0.03004768 -0.04647665  0.02112334  0.01069215\n",
      " -0.04362083 -0.0303404   0.097255   -0.01360076  0.01257121  0.09030977\n",
      "  0.07189948  0.10534236  0.01616951 -0.06354837]\n",
      "test loss 0.2094899793641913\n",
      "[-0.03124381  0.06610985 -0.04951772 -0.11115491  0.01011485  0.00886223\n",
      "  0.24967149  0.03501763 -0.03174744 -0.01744306 -0.03438976 -0.00424364\n",
      " -0.08600125 -0.02466663 -0.01702902  0.45107384 -0.04364514 -0.03413962\n",
      " -0.03466057 -0.06112092 -0.03582728 -0.02871766 -0.14832873 -0.01422811\n",
      " -0.0333581   0.10307546 -0.0260634  -0.35728429  0.05722615 -0.10266798\n",
      "  0.09938409  0.06103415  0.03864385  0.02296969 -0.09703671 -0.03730406\n",
      " -0.05714902 -0.02640927 -0.1141227   0.21295483  0.02567113  0.12096347\n",
      "  0.03628893  0.19837247  0.2538409   0.15087155  0.14045616  0.2138335\n",
      " -0.18978219  0.04262736  0.03737452 -0.05254583  0.00644532  0.01335894\n",
      " -0.04414    -0.03136349  0.09449592 -0.00705911  0.00713443  0.10522931\n",
      "  0.07122565  0.09253748  0.01492125 -0.05679309]\n",
      "test loss 0.20932308165829855\n",
      "[-0.02428935  0.06648341 -0.04270439 -0.1023545   0.00903732  0.00287368\n",
      "  0.2402312   0.03541808 -0.03441713 -0.01983088 -0.04915725 -0.00594035\n",
      " -0.09197584 -0.01355733 -0.01555608  0.44856694 -0.03949931 -0.03574453\n",
      " -0.03448477 -0.06314488 -0.04260965 -0.02868703 -0.15067419 -0.01117118\n",
      " -0.03957665  0.09905418 -0.03443343 -0.3574775   0.06890988 -0.09951656\n",
      "  0.10175552  0.06117783  0.04105992  0.02285386 -0.1030091  -0.03227886\n",
      " -0.05671312 -0.02786564 -0.1140111   0.21341283  0.03415925  0.12209933\n",
      "  0.02694731  0.19783877  0.2504024   0.15657511  0.12351813  0.21437091\n",
      " -0.18659635  0.04833464  0.04137288 -0.05112653  0.02171477  0.01836992\n",
      " -0.04343741 -0.03119022  0.10230662 -0.02166884  0.01937525  0.09260751\n",
      "  0.0650571   0.10123389  0.02735848 -0.06888114]\n",
      "test loss 0.20896157882813146\n",
      "[-0.02341088  0.06439187 -0.05252725 -0.10499589  0.00992756  0.01168002\n",
      "  0.25161478  0.03682137 -0.02787535 -0.01640496 -0.03890595 -0.00587418\n",
      " -0.09533338 -0.01288474 -0.01891846  0.44671958 -0.04351135 -0.04490027\n",
      " -0.03058438 -0.05807998 -0.03830233 -0.02910994 -0.14596159 -0.01862089\n",
      " -0.03184871  0.10165471 -0.02312558 -0.35051106  0.05780029 -0.10000164\n",
      "  0.10499412  0.05938258  0.04221498  0.02341967 -0.10855245 -0.0325866\n",
      " -0.06498564 -0.02483436 -0.11752702  0.20979187  0.03110821  0.12727163\n",
      "  0.03030485  0.20651938  0.24956652  0.14790262  0.1314439   0.21721015\n",
      " -0.18642677  0.03997044  0.02697129 -0.04998887  0.01726423  0.01449383\n",
      " -0.03648057 -0.03774429  0.09880366 -0.01216728  0.0151226   0.0983227\n",
      "  0.06469293  0.09298764  0.01210254 -0.05835742]\n",
      "test loss 0.20930100340651495\n",
      "[-2.31278490e-02  6.69533989e-02 -4.08864878e-02 -1.12826375e-01\n",
      "  9.62376800e-03  1.81002695e-04  2.38527463e-01  3.76073372e-02\n",
      " -3.35858064e-02 -1.64528296e-02 -4.37186656e-02 -4.52634565e-03\n",
      " -8.64670885e-02 -1.98657190e-02 -1.85621276e-02  4.50479477e-01\n",
      " -3.73243424e-02 -4.22179966e-02 -3.24550273e-02 -6.01822451e-02\n",
      " -3.51517755e-02 -2.91937441e-02 -1.39042474e-01 -2.09813081e-02\n",
      " -4.12773177e-02  1.04054261e-01 -2.81768263e-02 -3.54432203e-01\n",
      "  6.72638457e-02 -1.09951509e-01  1.04240749e-01  5.56352491e-02\n",
      "  4.07361943e-02  2.35419476e-02 -9.69333183e-02 -3.35428534e-02\n",
      " -6.01387473e-02 -2.84406865e-02 -1.11746214e-01  2.06931835e-01\n",
      "  2.50220688e-02  1.20313361e-01  3.59761032e-02  2.08588009e-01\n",
      "  2.48333891e-01  1.42681985e-01  1.31592154e-01  2.14082377e-01\n",
      " -1.92117174e-01  5.67311832e-02  3.24925836e-02 -4.60580735e-02\n",
      "  2.68999000e-02  6.15344314e-03 -4.27849164e-02 -2.81594554e-02\n",
      "  9.85482602e-02 -5.49381083e-03  9.21212095e-03  9.30293754e-02\n",
      "  6.60197448e-02  9.76227624e-02  1.73349582e-02 -6.17898606e-02]\n",
      "test loss 0.20952085765440104\n",
      "mean valloss 0.20927307073782403\n"
     ]
    }
   ],
   "source": [
    "#ridge\n",
    "result = []\n",
    "pred_test = np.zeros((len(test_x)))\n",
    "train_roc, val_roc = [], []\n",
    "\n",
    "ans = pd.DataFrame(columns=[\"item_id\", \"deal_probability\"])\n",
    "folds = pd.read_csv(\"data/cvFolds.csv\")\n",
    "\n",
    "for j in range(1, 8):\n",
    "    train_idx = folds[folds.fold!=j].index.values\n",
    "    test_idx = folds[folds.fold==j].index.values\n",
    "    xtr = x[train_idx]\n",
    "    ytr = y[train_idx]\n",
    "    xval = x[test_idx]\n",
    "    yval = y[test_idx]\n",
    "    val_id = traindex[test_idx]\n",
    "    \n",
    "    model = Ridge(alpha=1e-5)\n",
    "    model.fit(xtr, ytr)\n",
    "    print(model.coef_)\n",
    "    \n",
    "    pred_val = model.predict(xval)\n",
    "    pred_val = np.clip(pred_val, 0.0, 1.0)\n",
    "    #pred_val = np.where(pred_val < 0.005, 0, pred_val)\n",
    "    loss_val = np.sqrt(mean_squared_error(yval, pred_val))\n",
    "    ans_ = pd.DataFrame({\"item_id\": val_id, \"deal_probability\": pred_val})\n",
    "    ans = pd.concat((ans, ans_), axis=0)\n",
    "    \n",
    "    pred_test += np.clip(model.predict(test_x), 0.0, 1.0)\n",
    "    val_roc.append(loss_val)\n",
    "    print(\"test loss\", loss_val)\n",
    "\n",
    "print(\"mean valloss\", np.mean(val_roc))\n",
    "\n",
    "ans.to_csv(folder+\"ridge1_cvPreds_all.csv\", index=False)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"item_id\"] = test_id\n",
    "sub[\"deal_probability\"] = pred_test/7\n",
    "sub[\"deal_probability\"] .clip(0.0, 1.0, inplace=True)\n",
    "sub.to_csv(folder+\"ridge1_testPreds_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.21063318145558974\n",
      "test loss 0.21110201524620142\n",
      "test loss 0.21108758374981984\n",
      "test loss 0.21105918924018377\n",
      "test loss 0.21066529031168987\n",
      "test loss 0.21118129877943395\n",
      "test loss 0.21131949660528926\n",
      "mean valloss 0.21100686505545824\n"
     ]
    }
   ],
   "source": [
    "#extra tree\n",
    "params = {\"max_depth\": 5,\n",
    "          \"min_samples_leaf\": 100,\n",
    "          \"max_features\": 1.0,\n",
    "          \"n_estimators\": 10,\n",
    "         \"random_state\": 0}\n",
    "result = []\n",
    "pred_test = np.zeros((len(test_x)))\n",
    "train_roc, val_roc = [], []\n",
    "ans = pd.DataFrame(columns=[\"item_id\", \"deal_probability\"])\n",
    "folds = pd.read_csv(\"data/cvFolds.csv\")\n",
    "\n",
    "for j in range(1, 8):\n",
    "    train_idx = folds[folds.fold!=j].index.values\n",
    "    test_idx = folds[folds.fold==j].index.values\n",
    "    xtr = x[train_idx]\n",
    "    ytr = y[train_idx]\n",
    "    xval = x[test_idx]\n",
    "    yval = y[test_idx]\n",
    "    val_id = traindex[test_idx]\n",
    "    \n",
    "    model = ExtraTreesRegressor(**params)\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    pred_val = model.predict(xval)\n",
    "    pred_val = np.clip(pred_val, 0.0, 1.0)\n",
    "    #pred_val = np.where(pred_val < 0.005, 0, pred_val)\n",
    "    loss_val = np.sqrt(mean_squared_error(yval, pred_val))\n",
    "    ans_ = pd.DataFrame({\"item_id\": val_id, \"deal_probability\": pred_val})\n",
    "    ans = pd.concat((ans, ans_), axis=0)\n",
    "    \n",
    "    pred_test += np.clip(model.predict(test_x), 0.0, 1.0)\n",
    "    val_roc.append(loss_val)\n",
    "    print(\"test loss\", loss_val)\n",
    "\n",
    "print(\"mean valloss\", np.mean(val_roc))\n",
    "\n",
    "ans.to_csv(folder+\"exttree1_cvPreds_all_10.csv\", index=False)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"item_id\"] = test_id\n",
    "sub[\"deal_probability\"] = pred_test/7\n",
    "sub[\"deal_probability\"] .clip(0.0, 1.0, inplace=True)\n",
    "sub.to_csv(folder+\"exttree1_testPreds_all_10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 400 rounds.\n",
      "[200]\ttrain's rmse: 0.211221\tvalid's rmse: 0.211257\n",
      "[400]\ttrain's rmse: 0.20842\tvalid's rmse: 0.209041\n",
      "[600]\ttrain's rmse: 0.207703\tvalid's rmse: 0.208874\n",
      "[800]\ttrain's rmse: 0.207133\tvalid's rmse: 0.208809\n",
      "[1000]\ttrain's rmse: 0.206636\tvalid's rmse: 0.208767\n",
      "[1200]\ttrain's rmse: 0.206153\tvalid's rmse: 0.208734\n",
      "[1400]\ttrain's rmse: 0.205692\tvalid's rmse: 0.208715\n",
      "[1600]\ttrain's rmse: 0.205252\tvalid's rmse: 0.208698\n",
      "[1800]\ttrain's rmse: 0.204825\tvalid's rmse: 0.208687\n",
      "[2000]\ttrain's rmse: 0.20441\tvalid's rmse: 0.208679\n",
      "[2200]\ttrain's rmse: 0.203997\tvalid's rmse: 0.208675\n",
      "[2400]\ttrain's rmse: 0.203578\tvalid's rmse: 0.20867\n",
      "[2600]\ttrain's rmse: 0.20318\tvalid's rmse: 0.208671\n",
      "[2800]\ttrain's rmse: 0.202793\tvalid's rmse: 0.208662\n",
      "[3000]\ttrain's rmse: 0.202408\tvalid's rmse: 0.208665\n",
      "[3200]\ttrain's rmse: 0.202024\tvalid's rmse: 0.208661\n",
      "[3400]\ttrain's rmse: 0.201651\tvalid's rmse: 0.208654\n",
      "[3600]\ttrain's rmse: 0.201272\tvalid's rmse: 0.208651\n",
      "[3800]\ttrain's rmse: 0.200904\tvalid's rmse: 0.208653\n",
      "[4000]\ttrain's rmse: 0.200546\tvalid's rmse: 0.208649\n",
      "[4200]\ttrain's rmse: 0.200185\tvalid's rmse: 0.208651\n",
      "Early stopping, best iteration is:\n",
      "[3959]\ttrain's rmse: 0.200625\tvalid's rmse: 0.208648\n",
      "test loss 0.20864766178989388\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[200]\ttrain's rmse: 0.211161\tvalid's rmse: 0.211745\n",
      "[400]\ttrain's rmse: 0.208376\tvalid's rmse: 0.209425\n",
      "[600]\ttrain's rmse: 0.20766\tvalid's rmse: 0.209214\n",
      "[800]\ttrain's rmse: 0.207098\tvalid's rmse: 0.209134\n",
      "[1000]\ttrain's rmse: 0.206585\tvalid's rmse: 0.209081\n",
      "[1200]\ttrain's rmse: 0.206108\tvalid's rmse: 0.209046\n",
      "[1400]\ttrain's rmse: 0.205648\tvalid's rmse: 0.209016\n",
      "[1600]\ttrain's rmse: 0.205213\tvalid's rmse: 0.208996\n",
      "[1800]\ttrain's rmse: 0.204766\tvalid's rmse: 0.208982\n",
      "[2000]\ttrain's rmse: 0.204343\tvalid's rmse: 0.208975\n",
      "[2200]\ttrain's rmse: 0.203927\tvalid's rmse: 0.208963\n",
      "[2400]\ttrain's rmse: 0.203513\tvalid's rmse: 0.208957\n",
      "[2600]\ttrain's rmse: 0.203116\tvalid's rmse: 0.20895\n",
      "[2800]\ttrain's rmse: 0.202722\tvalid's rmse: 0.208943\n",
      "[3000]\ttrain's rmse: 0.20233\tvalid's rmse: 0.208935\n",
      "[3200]\ttrain's rmse: 0.201944\tvalid's rmse: 0.208934\n",
      "[3400]\ttrain's rmse: 0.201572\tvalid's rmse: 0.208936\n",
      "[3600]\ttrain's rmse: 0.201199\tvalid's rmse: 0.20893\n",
      "[3800]\ttrain's rmse: 0.200826\tvalid's rmse: 0.208932\n",
      "[4000]\ttrain's rmse: 0.200469\tvalid's rmse: 0.208936\n",
      "Early stopping, best iteration is:\n",
      "[3604]\ttrain's rmse: 0.201192\tvalid's rmse: 0.20893\n",
      "test loss 0.20892958882648408\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[200]\ttrain's rmse: 0.211132\tvalid's rmse: 0.211735\n",
      "[400]\ttrain's rmse: 0.208343\tvalid's rmse: 0.209546\n",
      "[600]\ttrain's rmse: 0.207625\tvalid's rmse: 0.209389\n",
      "[800]\ttrain's rmse: 0.207055\tvalid's rmse: 0.209323\n",
      "[1000]\ttrain's rmse: 0.206531\tvalid's rmse: 0.20928\n",
      "[1200]\ttrain's rmse: 0.206048\tvalid's rmse: 0.209258\n",
      "[1400]\ttrain's rmse: 0.205579\tvalid's rmse: 0.209242\n",
      "[1600]\ttrain's rmse: 0.205138\tvalid's rmse: 0.209231\n",
      "[1800]\ttrain's rmse: 0.204707\tvalid's rmse: 0.20922\n",
      "[2000]\ttrain's rmse: 0.204283\tvalid's rmse: 0.20921\n",
      "[2200]\ttrain's rmse: 0.203864\tvalid's rmse: 0.209204\n",
      "[2400]\ttrain's rmse: 0.203451\tvalid's rmse: 0.209207\n",
      "[2600]\ttrain's rmse: 0.203055\tvalid's rmse: 0.209205\n",
      "Early stopping, best iteration is:\n",
      "[2201]\ttrain's rmse: 0.203862\tvalid's rmse: 0.209204\n",
      "test loss 0.209203518308068\n",
      "Training until validation scores don't improve for 400 rounds.\n",
      "[200]\ttrain's rmse: 0.211151\tvalid's rmse: 0.211703\n",
      "[400]\ttrain's rmse: 0.208353\tvalid's rmse: 0.209488\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5d2d752bab39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mvalid_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/oko/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    202\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/oko/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1526\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1527\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lgbm\n",
    "lgbm_params =  {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        \"boost_from_average\": False,\n",
    "        #'max_depth': 2,\n",
    "        'num_leaves': 73,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'feature_fraction': 0.5,\n",
    "        'min_data_in_leaf': 50,\n",
    "        #'reg_alpha': 0.6,\n",
    "        #'reg_lambda': 0.4,\n",
    "        'min_sum_hessian_in_leaf': 2.0,\n",
    "        'learning_rate': 0.01,\n",
    "        'seed': 0,\n",
    "        'verbose': -1\n",
    "    }\n",
    "\n",
    "result = []\n",
    "pred_test = np.zeros((len(test_x)))\n",
    "train_roc, val_roc = [], []\n",
    "ans = pd.DataFrame(columns=[\"item_id\", \"deal_probability\"])\n",
    "folds = pd.read_csv(\"data/cvFolds.csv\")\n",
    "\n",
    "for j in range(1, 8):\n",
    "    train_idx = folds[folds.fold!=j].index.values\n",
    "    test_idx = folds[folds.fold==j].index.values\n",
    "    xtr = x[train_idx]\n",
    "    ytr = y[train_idx]\n",
    "    xval = x[test_idx]\n",
    "    yval = y[test_idx]\n",
    "    val_id = traindex[test_idx]\n",
    "    \n",
    "    lgtrain = lgb.Dataset(xtr, ytr)\n",
    "    lgvalid = lgb.Dataset(xval, yval)\n",
    "\n",
    "    lgb_clf = lgb.train(\n",
    "        lgbm_params,\n",
    "        lgtrain,\n",
    "        num_boost_round=100000,\n",
    "        valid_sets=[lgtrain, lgvalid],\n",
    "        valid_names=['train','valid'],\n",
    "        early_stopping_rounds=400,\n",
    "        verbose_eval=200\n",
    "    )\n",
    "    \n",
    "    pred_val = lgb_clf.predict(xval, num_iteration=lgb_clf.best_iteration)\n",
    "    pred_val = np.clip(pred_val, 0.0, 1.0)\n",
    "    loss_val = np.sqrt(mean_squared_error(yval, pred_val))\n",
    "    print(\"test loss\", loss_val)\n",
    "    \n",
    "    pred_test += np.clip(lgb_clf.predict(test_x, num_iteration=lgb_clf.best_iteration), 0.0, 1.0)\n",
    "    val_roc.append(loss_val)\n",
    "    \n",
    "    ans_ = pd.DataFrame({\"item_id\": val_id, \"deal_probability\": pred_val})\n",
    "    ans = pd.concat((ans, ans_), axis=0)\n",
    "\n",
    "print(\"mean valloss\", np.mean(val_roc))\n",
    "\n",
    "ans.to_csv(folder+\"lgbm1_cvPreds_all.csv\", index=False)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"item_id\"] = test_id\n",
    "sub[\"deal_probability\"] = pred_test/7\n",
    "sub[\"deal_probability\"] .clip(0.0, 1.0, inplace=True)\n",
    "sub.to_csv(folder+\"lgbm1_testPreds_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:0.411432\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[339]\teval-rmse:0.212982\n",
      "\n",
      "test loss 0.21298231988278543\n",
      "[0]\teval-rmse:0.411475\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[196]\teval-rmse:0.213282\n",
      "\n",
      "test loss 0.2132821498074323\n",
      "[0]\teval-rmse:0.411506\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[289]\teval-rmse:0.212495\n",
      "\n",
      "test loss 0.21249525848758216\n",
      "[0]\teval-rmse:0.411466\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[137]\teval-rmse:0.213482\n",
      "\n",
      "test loss 0.21348192273251976\n",
      "[0]\teval-rmse:0.411597\n",
      "Will train until eval-rmse hasn't improved in 10 rounds.\n",
      "Stopping. Best iteration:\n",
      "[255]\teval-rmse:0.212076\n",
      "\n",
      "test loss 0.21207586167563877\n",
      "mean valloss 0.21286350251719172\n"
     ]
    }
   ],
   "source": [
    "#xgb\n",
    "xgb_params =  {\n",
    "        'task': 'train',\n",
    "        'booster': 'gblinear',\n",
    "        'objective': 'reg:linear',\n",
    "        'metric': 'rmse',\n",
    "        'max_depth': 5,\n",
    "        'max_leaves': 31,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bylevel': 0.5,\n",
    "        'min_child_weight': 100,\n",
    "        'eta': 0.05,\n",
    "        'silent': 1,\n",
    "        'verbose': 0\n",
    "    }  \n",
    "\n",
    "result = []\n",
    "pred_test = np.zeros((len(test_x)))\n",
    "train_roc, val_roc = [], []\n",
    "ans = pd.DataFrame(columns=[\"item_id\", \"deal_probability\"])\n",
    "folds = pd.read_csv(\"data/cvFolds.csv\")\n",
    "\n",
    "for j in range(1, 8):\n",
    "    train_idx = folds[folds.fold!=j].index.values\n",
    "    test_idx = folds[folds.fold==j].index.values\n",
    "    xtr = x[train_idx]\n",
    "    ytr = y[train_idx]\n",
    "    xval = x[test_idx]\n",
    "    yval = y[test_idx]\n",
    "    val_id = traindex[test_idx]\n",
    "    \n",
    "    dtrain =xgb.DMatrix(data = xtr, label = ytr)\n",
    "    dval =xgb.DMatrix(data = xval, label = yval)\n",
    "    watchlist = [(dval, 'eval')]\n",
    "    \n",
    "    xgb_clf = xgb.train(\n",
    "                            xgb_params,\n",
    "                            dtrain,\n",
    "                            num_boost_round=15000,\n",
    "                            early_stopping_rounds=400,\n",
    "                            verbose_eval=1000,\n",
    "                            evals=watchlist\n",
    "                            )\n",
    "    \n",
    "    pred_val = xgb_clf.predict(dval, ntree_limit=xgb_clf.best_ntree_limit)\n",
    "    pred_val = np.clip(pred_val, 0.0, 1.0)\n",
    "    loss_val = np.sqrt(mean_squared_error(yval, pred_val))\n",
    "    \n",
    "    dtest =xgb.DMatrix(data = test_x)\n",
    "    pred_test += np.clip(xgb_clf.predict(dtest, ntree_limit=xgb_clf.best_ntree_limit), 0.0, 1.0)\n",
    "    val_roc.append(loss_val)\n",
    "    \n",
    "    ans_ = pd.DataFrame({\"item_id\": val_id, \"deal_probability\": pred_val})\n",
    "    ans = pd.concat((ans, ans_), axis=0)\n",
    "    \n",
    "    print(\"test loss\", loss_val)\n",
    "\n",
    "print(\"mean valloss\", np.mean(val_roc))\n",
    "\n",
    "ans.to_csv(folder+\"xgblinear1_cvPreds.csv\", index=False)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"item_id\"] = test_id\n",
    "sub[\"deal_probability\"] = pred_test/7\n",
    "sub[\"deal_probability\"] .clip(0.0, 1.0, inplace=True)\n",
    "sub.to_csv(folder+\"xgblinear1_testPreds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn uni\n",
    "params = {\"n_neighbors\": 5,\n",
    "          \"weights\": \"uniform\",\n",
    "          \"leaf_size\": 30}\n",
    "result = []\n",
    "pred_test = np.zeros((len(test_x)))\n",
    "train_roc, val_roc = [], []\n",
    "ans = pd.DataFrame(columns=[\"item_id\", \"deal_probability\"])\n",
    "folds = pd.read_csv(\"data/cvFolds.csv\")\n",
    "\n",
    "for j in range(1, 8):\n",
    "    train_idx = folds[folds.fold!=j].index.values\n",
    "    test_idx = folds[folds.fold==j].index.values\n",
    "    xtr = x[train_idx]\n",
    "    ytr = y[train_idx]\n",
    "    xval = x[test_idx]\n",
    "    yval = y[test_idx]\n",
    "    val_id = traindex[test_idx]\n",
    "    \n",
    "    model = neighbors.KNeighborsRegressor(**params)\n",
    "    model.fit(xtr, ytr)\n",
    "    \n",
    "    pred_val = model.predict(xval)\n",
    "    pred_val = np.clip(pred_val, 0.0, 1.0)\n",
    "    #pred_val = np.where(pred_val < 0.005, 0, pred_val)\n",
    "    loss_val = np.sqrt(mean_squared_error(yval, pred_val))\n",
    "    ans_ = pd.DataFrame({\"item_id\": val_id, \"deal_probability\": pred_val})\n",
    "    ans = pd.concat((ans, ans_), axis=0)\n",
    "    \n",
    "    pred_test += np.clip(model.predict(test_x), 0.0, 1.0)\n",
    "    val_roc.append(loss_val)\n",
    "    print(\"test loss\", loss_val)\n",
    "\n",
    "print(\"mean valloss\", np.mean(val_roc))\n",
    "\n",
    "ans.to_csv(folder+\"knnuni1_cvPreds.csv\", index=False)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub[\"item_id\"] = test_id\n",
    "sub[\"deal_probability\"] = pred_test/7\n",
    "sub[\"deal_probability\"] .clip(0.0, 1.0, inplace=True)\n",
    "sub.to_csv(folder+\"knnuni1_textPreds.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
